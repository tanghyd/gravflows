{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # set available gpus before importing torch\n",
    "\n",
    "# utils\n",
    "import time\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "# typing\n",
    "from typing import Optional, Union, List, Dict, Tuple\n",
    "\n",
    "# modelling\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# multiprocessing\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "\n",
    "# visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astronomy\n",
    "import pycbc.psd\n",
    "from pycbc.detector import Detector\n",
    "from pycbc.waveform import get_waveform_filter_length_in_time, get_td_waveform, get_fd_waveform\n",
    "\n",
    "from lal import MSUN_SI, REARTH_SI, C_SI, PC_SI\n",
    "from lalsimulation import (\n",
    "    SimInspiralTransformPrecessingNewInitialConditions,\n",
    "    SimInspiralChooseFDWaveform,\n",
    "    SimInspiralFD,\n",
    "    SimInspiralImplementedFDApproximants,\n",
    "    GetApproximantFromString\n",
    ")\n",
    "\n",
    "# astronomy - typing\n",
    "# from gwpy.frequencyseries import FrequencySeries\n",
    "# from gwpy.timeseries import TimeSeries\n",
    "# from pycbc.types import FrequencySeries, TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from lfigw.waveform_generator import source_frame_to_radiation, is_fd_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# import numpy as np\n",
    "# import h5py\n",
    "# from pathlib import Path\n",
    "# from sklearn.utils.extmath import randomized_svd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# class SVDBasis(object):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.whitening_dict = {}\n",
    "#         self.standardization_dict = {}\n",
    "#         self.T_matrices = None\n",
    "#         self.T_matrices_deriv = None\n",
    "\n",
    "#     def generate_basis(self, training_data, n, method='random'):\n",
    "#         \"\"\"Generate the SVD basis from training data and store it.\n",
    "\n",
    "#         The SVD decomposition takes\n",
    "\n",
    "#         training_data = U @ diag(s) @ Vh\n",
    "\n",
    "#         where U and Vh are unitary.\n",
    "\n",
    "#         Arguments:\n",
    "#             training_data {array} -- waveforms in frequency domain\n",
    "\n",
    "#         Keyword Arguments:\n",
    "#             n {int} -- number of basis elements to keep.\n",
    "#                        n=0 keeps all basis elements. (default: {0})\n",
    "#         \"\"\"\n",
    "#         print(f'training_data: {training_data}')\n",
    "#         print(f'n: {n}')\n",
    "\n",
    "#         if method == 'random':\n",
    "#             U, s, Vh = randomized_svd(training_data, n)\n",
    "\n",
    "#             self.Vh = Vh.astype(np.complex64)\n",
    "#             self.V = self.Vh.T.conj()\n",
    "\n",
    "#             self.n = n\n",
    "\n",
    "#         elif method == 'scipy':\n",
    "#             # Code below uses scipy's svd tool. Likely slower.\n",
    "\n",
    "#             U, s, Vh = scipy.linalg.svd(training_data, full_matrices=False)\n",
    "#             V = Vh.T.conj()\n",
    "\n",
    "#             if (n == 0) or (n > len(V)):\n",
    "#                 self.V = V\n",
    "#                 self.Vh = Vh\n",
    "#             else:\n",
    "#                 self.V = V[:, :n]\n",
    "#                 self.Vh = Vh[:n, :]\n",
    "\n",
    "#             self.n = len(self.Vh)\n",
    "\n",
    "#     def basis_coefficients_to_fseries(self, coefficients):\n",
    "#         \"\"\"Convert from basis coefficients to frequency series.\n",
    "\n",
    "#         Arguments:\n",
    "#             coefficients {array} -- basis coefficients\n",
    "\n",
    "#         Returns:\n",
    "#             array -- frequency series\n",
    "#         \"\"\"\n",
    "\n",
    "#         return coefficients @ self.Vh\n",
    "\n",
    "#     def fseries_to_basis_coefficients(self, fseries):\n",
    "#         \"\"\"Convert from frequency series to basis coefficients.\n",
    "\n",
    "#         Arguments:\n",
    "#             fseries {array} -- frequency series\n",
    "\n",
    "#         Returns:\n",
    "#             array -- basis coefficients\n",
    "#         \"\"\"\n",
    "\n",
    "#         return fseries @ self.V\n",
    "\n",
    "#     #\n",
    "#     # Time translation\n",
    "#     #\n",
    "\n",
    "#     def init_time_translation(self, t_min, t_max, Nt, f_grid):\n",
    "#         \"\"\"Initialize the time translation matrices.\n",
    "\n",
    "#         The time translation in frequency domain corresponds to multiplication\n",
    "#         by e^{ - 2 pi i f dt }. If we only have waveforms in terms of basis\n",
    "#         coefficients, however, this is quite expensive: first one must\n",
    "#         transform to frequency domain, then time translate, then transform\n",
    "#         back to the reduced basis domain. Generally the dimensionality of\n",
    "#         FD waveforms will be much higher than the dimension of the reduced\n",
    "#         basis, so this is very costly.\n",
    "\n",
    "#         This function pre-computes N x N matrices in the reduced basis domain,\n",
    "#         where N is the dimension of the reduced basis. Matrices are computed\n",
    "#         at a discrete set of dt's. Later, interpolation is used to compute time\n",
    "#         translated coefficients away from these discrete points.\n",
    "\n",
    "#         Arguments:\n",
    "#             t_min {float} -- minimum value of dt\n",
    "#             t_max {float} -- maximum value of dt\n",
    "#             Nt {int} -- number of discrete points at which to compute matrices\n",
    "#             f_grid {array} -- frequencies at which FD waveforms are evaluated\n",
    "#         \"\"\"\n",
    "\n",
    "#         self.t_grid = np.linspace(t_min, t_max, num=Nt, endpoint=True,\n",
    "#                                   dtype=np.float32)\n",
    "\n",
    "#         self.T_matrices = np.empty((Nt, self.n, self.n),\n",
    "#                                    dtype=np.complex64)\n",
    "#         self.T_matrices_deriv = np.empty((Nt, self.n, self.n),\n",
    "#                                          dtype=np.complex64)\n",
    "\n",
    "#         print('Building time translation matrices.')\n",
    "#         for i in tqdm(range(Nt)):\n",
    "\n",
    "#             # Translation by dt in FD is multiplication by e^{- 2 pi i f dt}\n",
    "#             T_fd = np.exp(- 2j * np.pi * self.t_grid[i] * f_grid)\n",
    "#             T_deriv_fd = - 2j * np.pi * f_grid * T_fd\n",
    "\n",
    "#             # Convert to FD, apply t translation, convert to reduced basis\n",
    "#             T_basis = (self.Vh * T_fd) @ self.V\n",
    "#             T_deriv_basis = (self.Vh * T_deriv_fd) @ self.V\n",
    "\n",
    "#             self.T_matrices[i] = T_basis\n",
    "#             self.T_matrices_deriv[i] = T_deriv_basis\n",
    "\n",
    "#     def time_translate(self, coefficients, dt, interpolation='linear'):\n",
    "#         \"\"\"Calculate basis coefficients for a time-translated waveform.\n",
    "\n",
    "#         The new waveform h_new(t) = h_old(t - dt). In other words, if the\n",
    "#         original merger time is t=0, then the new merger time is t=dt.\n",
    "\n",
    "#         In frequency domain, this corresponds to multiplication by\n",
    "#         e^{ - 2 pi i f dt }.\n",
    "\n",
    "#         This method is capable of linear or cubic interpolation.\n",
    "\n",
    "#         Arguments:\n",
    "#             coefficients {array} -- basis coefficients of initial waveform\n",
    "#             dt {float} -- time translation\n",
    "\n",
    "#         Keyword Arguments:\n",
    "#             interpolation {str} -- 'linear' or 'cubic' interpolation\n",
    "#                                    (default: {'linear'})\n",
    "\n",
    "#         Returns:\n",
    "#             array -- basis coefficients of time-translated waveform\n",
    "#         \"\"\"\n",
    "\n",
    "#         pos = np.searchsorted(self.t_grid, dt, side='right') - 1\n",
    "\n",
    "#         if self.t_grid[pos] == dt:\n",
    "\n",
    "#             # No interpolation needed\n",
    "#             translated = coefficients @ self.T_matrices[pos]\n",
    "\n",
    "#         else:\n",
    "#             t_left = self.t_grid[pos]\n",
    "#             t_right = self.t_grid[pos+1]\n",
    "\n",
    "#             # Interpolation parameter u(dt) defined so that:\n",
    "#             #           u(t_left) = 0\n",
    "#             #           u(t_right) = 1\n",
    "\n",
    "#             u = (dt - t_left) / (t_right - t_left)\n",
    "\n",
    "#             # Require coefficients evaluated on boundaries of interval\n",
    "#             y_left = coefficients @ self.T_matrices[pos]\n",
    "#             y_right = coefficients @ self.T_matrices[pos+1]\n",
    "\n",
    "#             if interpolation == 'linear':\n",
    "\n",
    "#                 translated = y_left * (1 - u) + y_right * u\n",
    "\n",
    "#             elif interpolation == 'cubic':\n",
    "\n",
    "#                 # Also require derivative of coefficients wrt dt\n",
    "#                 dydt_left = coefficients @ self.T_matrices_deriv[pos]\n",
    "#                 dydt_right = coefficients @ self.T_matrices_deriv[pos+1]\n",
    "\n",
    "#                 # Cubic interpolation over interval\n",
    "#                 # See https://en.wikipedia.org/wiki/Cubic_Hermite_spline\n",
    "\n",
    "#                 h00 = 2*(u**3) - 3*(u**2) + 1\n",
    "#                 h10 = u**3 - 2*(u**2) + u\n",
    "#                 h01 = -2*(u**3) + 3*(u**2)\n",
    "#                 h11 = u**3 - u**2\n",
    "\n",
    "#                 translated = (y_left * h00\n",
    "#                               + dydt_left * h10 * (t_right - t_left)\n",
    "#                               + y_right * h01\n",
    "#                               + dydt_right * h11 * (t_right - t_left))\n",
    "\n",
    "#         return translated\n",
    "\n",
    "#     #\n",
    "#     # Whitening\n",
    "#     #\n",
    "#     # At present, we must know the fiducial and new noise PSD in advance, in\n",
    "#     # order to prepare the transformation matrices for reduced basis\n",
    "#     # coefficients. This is needed for dealing with detectors with different\n",
    "#     # PSDs.\n",
    "#     #\n",
    "#     # In the future, when we draw PSDs at random at train time, this will need\n",
    "#     # to be modified.\n",
    "#     #\n",
    "\n",
    "#     def init_whitening(self, ref_psd_name, ref_psd,\n",
    "#                        new_psd_name, new_psd):\n",
    "#         \"\"\"Initialize whitening.\n",
    "\n",
    "#         Constructs and saves the whitening matrix for changing from a reference\n",
    "#         to a new noise PSD. This matrix acts on vectors of reduced basis\n",
    "#         coefficients.\n",
    "\n",
    "#         Arguments:\n",
    "#             ref_psd_name {str} -- label for fiducial PSD\n",
    "#             ref_psd {array} -- frequency series for fiducial PSd\n",
    "#             new_psd_name {str} -- label for new PSD\n",
    "#             new_psd {array} -- frequency series for new PSD\n",
    "#         \"\"\"\n",
    "\n",
    "#         if ((new_psd_name != ref_psd_name)\n",
    "#                 and (new_psd_name not in self.whitening_dict.keys())):\n",
    "\n",
    "#             # ref_psd = np.array(ref_psd)\n",
    "#             # new_psd = np.array(new_psd)\n",
    "\n",
    "#             whitening_FD = (ref_psd / new_psd) ** 0.5\n",
    "\n",
    "#             # Convert to float32 *after* dividing. PSDs can have very small\n",
    "#             # numbers.\n",
    "#             whitening_FD = whitening_FD.astype(np.float32)\n",
    "\n",
    "#             # Convert to RB representation\n",
    "#             whitening_RB = (self.Vh * whitening_FD) @ self.V\n",
    "\n",
    "#             whitening_RB = whitening_RB.astype(np.complex64)\n",
    "\n",
    "#             self.ref_psd_name = ref_psd_name\n",
    "#             self.whitening_dict[new_psd_name] = whitening_RB\n",
    "\n",
    "#     def whiten(self, coefficients, psd_name):\n",
    "#         \"\"\"Whiten a waveform, given as a vector of reduced-basis coefficients.\n",
    "#         Waveform is assumed to already be white wrt reference PSD.\n",
    "\n",
    "#         Whitening must be first initialized with with init_whitening method.\n",
    "\n",
    "#         Arguments:\n",
    "#             coefficients {array} -- basis coefficients of initial waveform\n",
    "#             psd_name {str} -- label for new PSD\n",
    "\n",
    "#         Returns:\n",
    "#             array -- basis coefficients for whitened waveform\n",
    "#         \"\"\"\n",
    "\n",
    "#         if psd_name != self.ref_psd_name:\n",
    "#             return coefficients @ self.whitening_dict[psd_name]\n",
    "\n",
    "#         else:\n",
    "#             return coefficients\n",
    "\n",
    "#     #\n",
    "#     # Truncation\n",
    "#     #\n",
    "\n",
    "#     def truncate(self, n):\n",
    "\n",
    "#         self.V = self.V[:, :n]\n",
    "#         self.Vh = self.Vh[:n, :]\n",
    "\n",
    "#         for ifo in self.standardization_dict.keys():\n",
    "#             self.standardization_dict[ifo] = self.standardization_dict[ifo][:n]\n",
    "\n",
    "#         for psd in self.whitening_dict.keys():\n",
    "#             self.whitening_dict[psd] = self.whitening_dict[psd][:n, :n]\n",
    "\n",
    "#         if self.T_matrices is not None:\n",
    "#             self.T_matrices = self.T_matrices[:, :n, :n]\n",
    "#             self.T_matrices_deriv = self.T_matrices_deriv[:, :n, :n]\n",
    "\n",
    "#         self.n = n\n",
    "\n",
    "#     #\n",
    "#     # Standardization\n",
    "#     #\n",
    "#     # Given a whitened noisy waveform, we want to rescale each component to\n",
    "#     # have unit variance. This is to improve neural network training. The mean\n",
    "#     # should already be zero.\n",
    "#     #\n",
    "\n",
    "#     def init_standardization(self, ifo, h_array, noise_std):\n",
    "\n",
    "#         # Standard deviation of data. Divide by sqrt(2) because we want real\n",
    "#         # and imaginary parts to have unit standard deviation.\n",
    "#         std = np.std(h_array, axis=0) / np.sqrt(2)\n",
    "\n",
    "#         # Total standard deviation\n",
    "#         std_total = np.sqrt(std**2 + noise_std**2)\n",
    "\n",
    "#         self.standardization_dict[ifo] = 1.0 / std_total\n",
    "\n",
    "#     def standardize(self, h, ifo):\n",
    "\n",
    "#         return h * self.standardization_dict[ifo]\n",
    "\n",
    "#     #\n",
    "#     # File I/O\n",
    "#     #\n",
    "\n",
    "#     def save(self, directory='.', filename='reduced_basis.hdf5'):\n",
    "\n",
    "#         p = Path(directory)\n",
    "#         p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         f = h5py.File(p / filename, 'w')\n",
    "\n",
    "#         f.create_dataset('V', data=self.V,\n",
    "#                          compression='gzip', compression_opts=9)\n",
    "\n",
    "#         if self.standardization_dict != {}:\n",
    "#             std_group = f.create_group('std')\n",
    "#             for ifo, std in self.standardization_dict.items():\n",
    "#                 std_group.create_dataset(ifo, data=std,\n",
    "#                                          compression='gzip',\n",
    "#                                          compression_opts=9)\n",
    "\n",
    "#         f.close()\n",
    "\n",
    "#     def load(self, directory='.', filename='reduced_basis.hdf5'):\n",
    "\n",
    "#         p = Path(directory)\n",
    "\n",
    "#         f = h5py.File(p / filename, 'r')\n",
    "#         self.V = f['V'][:, :]\n",
    "\n",
    "#         if 'std' in f.keys():\n",
    "#             std_group = f['std']\n",
    "#             for ifo in std_group.keys():\n",
    "#                 self.standardization_dict[ifo] = std_group[ifo][:]\n",
    "\n",
    "#         f.close()\n",
    "\n",
    "#         self.Vh = self.V.T.conj()\n",
    "#         self.n = len(self.Vh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# author's numpy version of prior sampling\n",
    "def lfigw_sample_prior(self, n):\n",
    "    # transform prior ranges corresponding to uniformly sampled parameters\n",
    "    uniform_priors = np.zeros((self.nparams, 2))\n",
    "    for idx, param in enumerate(self.parameters):\n",
    "        uniform_priors[idx] = self.priors[param]\n",
    "\n",
    "        # transform prior domain in order to sample form uniform distribution\n",
    "        if param in ('theta_jn', 'tilt_1', 'tilt_2'):\n",
    "            uniform_priors[idx] = np.cos(uniform_priors[idx])  # we apply arccos after sampling\n",
    "        elif param == 'dec':\n",
    "            uniform_priors[idx] = np.sin(uniform_priors[idx])  # we apply arcsin after sampling\n",
    "        elif param == 'distance':\n",
    "            uniform_priors[idx] = uniform_priors[idx] ** 3.0  # we apply **(1/3) after sampling\n",
    "\n",
    "    # Draw uniform samples\n",
    "    draw = np.random.random((n, self.nparams))\n",
    "\n",
    "    samples = np.apply_along_axis(\n",
    "        lambda x: x*(uniform_priors[:, 1]- uniform_priors[:, 0]) + uniform_priors[:, 0],\n",
    "        axis=1, \n",
    "        arr=draw\n",
    "    )\n",
    "\n",
    "    def M_q_from_m1_m2(m1, m2):\n",
    "\n",
    "        M = m1 + m2\n",
    "        q = m2 / m1\n",
    "\n",
    "        return M, q\n",
    "\n",
    "    m1i = self.param_idx['mass_1']\n",
    "    m2i = self.param_idx['mass_2']\n",
    "\n",
    "    if ('M' in self.priors.keys()) and ('q' in self.priors.keys()):\n",
    "        M_min, M_max = self.priors['M']\n",
    "        q_min, q_max = self.priors['q']\n",
    "        m1_min, m1_max = self.priors['mass_1']\n",
    "        m2_min, m2_max = self.priors['mass_2']\n",
    "        for i in range(n):\n",
    "            m1, m2 = samples[i, [m1i, m2i]]\n",
    "            while True:\n",
    "                M, q = M_q_from_m1_m2(m1, m2)\n",
    "                if (m1 >= m2 and M >= M_min and M <= M_max\n",
    "                        and q >= q_min and q <= q_max):\n",
    "                    samples[i, [m1i, m2i]] = (m1, m2)\n",
    "                    break\n",
    "                else:\n",
    "                    m1 = m1_min + (m1_max - m1_min) * np.random.random()\n",
    "                    m2 = m2_min + (m2_max - m2_min) * np.random.random()\n",
    "    else:\n",
    "        # ONLY VALID OF M1, M2 HAVE THE SAME RANGES\n",
    "        samples[:, [m2i, m1i]] = np.sort(samples[:, [m1i, m2i]])\n",
    "\n",
    "\n",
    "    # Undo uniformity transformations\n",
    "    for idx, param in enumerate(self.parameters):\n",
    "        if param in ('theta_jn', 'tilt_1', 'tilt_2'):\n",
    "            samples[:, idx] = np.arccos(samples[:, idx])\n",
    "        elif param == 'dec':\n",
    "            samples[:, idx] = np.arcsin(samples[:, idx])\n",
    "        elif param == 'distance':\n",
    "            samples[:, idx] = samples[:, idx] ** (1.0/3.0)\n",
    "            \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def save_pair_plot(df: pd.DataFrame, filename: str, theme: str='ticks'):\n",
    "    #https://stackoverflow.com/questions/37612434/what-are-ways-to-speed-up-seaborns-pairplot\n",
    "    sns.set_style(theme)\n",
    "    sns_plot = sns.pairplot(df, corner=True, diag_kind='kde', kind='kde')\n",
    "    sns_plot.savefig(filename)\n",
    "    plt.clf()  # clean pairplot figure from sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ordered_parameters(spins: bool, spins_aligned: bool, inclination: bool, mass_ratio: bool=False) -> Tuple[str]:\n",
    "    \"\"\"Function genereates an ordered tuple of parameters.\n",
    "    \n",
    "    The index positions of each parameter in this list must be kept static for downstream tasks.\n",
    "    \"\"\"\n",
    "    if mass_ratio:\n",
    "        parameters = ['M', 'q']\n",
    "    else:\n",
    "        parameters = ['mass_1', 'mass_2']\n",
    "        \n",
    "    parameters.extend(['phase', 'time', 'distance'])\n",
    "\n",
    "    if spins:\n",
    "        if spins_aligned:\n",
    "            parameters.extend(['chi_1', 'chi_2'])\n",
    "        else:\n",
    "            if not inclination:\n",
    "                raise Exception('Precession requires nonzero inclination.')\n",
    "            parameters.extend(['a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl'])\n",
    "\n",
    "    if inclination:\n",
    "        parameters.extend(['theta_jn', 'psi'])\n",
    "\n",
    "    parameters.extend(['ra', 'dec'])\n",
    "    \n",
    "    return tuple(parameters)\n",
    "\n",
    "def generate_psd(\n",
    "    ifo: str,\n",
    "    delta_f: float,\n",
    "    f_max: float,\n",
    "    f_min: float,\n",
    "    event_dir: Optional[Union[Path, str]]=None,\n",
    ") -> pycbc.types.FrequencySeries:\n",
    "    \"\"\"Generate a power spectral density (PSD) as a Frequency Series given provided interferometer detector.\n",
    "    \n",
    "    Arguments:\n",
    "        ifo: {str} -- Interferometer name according to LALSimulation (minus SimNoisePSD prefix) - prefixed with \"PSD_\"\n",
    "        delta_f: {float} -- Frequency spacing (resolution) of the frequency series for the PSD\n",
    "        f_max: {float} -- The maximum frequency for the PSD - should be half the sampling rate (see: Nyquist frequency)\n",
    "        f_min_psd: {float} -- The minimum frequency for the PSD. May be different to f_min used when processing signals.\n",
    "        event_dir {pathlib.Path | str} -- The directory of the event, e.g. 'data/events/GW150914'. \n",
    "            If None, this implies the PSD is not loaded and so we get from PyCBC; else we load from file.\n",
    "\n",
    "    Returns:\n",
    "        psd -- The power spectral density generated by PyCBC given our arguments.\n",
    "    \"\"\"\n",
    "    # \"The PSD length should be the same as the length of Frequency Domain (FD) waveforms,\n",
    "    # which is determined from delta_f and f_max.\" - Green\n",
    "    psd_length = int(f_max / delta_f) + 1\n",
    "    \n",
    "    if event_dir is None:\n",
    "        psd = pycbc.psd.from_string(\n",
    "            psd_name=f'PSD_{ifo}',  # PSD name according to LALSimulation (minus SimNoisePSD prefix)\n",
    "            length=psd_length,\n",
    "            delta_f=delta_f,\n",
    "            low_freq_cutoff=f_min,  # freq below this value are set to zero.\n",
    "        )\n",
    "    else:\n",
    "        psd_filepath = event_dir / f'PSD_{ifo}.txt'\n",
    "        assert psd_filepath.is_file(), f'{psd_filepath} does not exist.'\n",
    "        psd = pycbc.psd.from_txt(\n",
    "            filename=psd_filepath,\n",
    "            length=psd_length,\n",
    "            delta_f=delta_f,\n",
    "            low_freq_cutoff=f_min,  # freq below this value are set to zero.\n",
    "            is_asd_file=False,\n",
    "        )\n",
    "        \n",
    "    # To avoid division by 0 when whitening, set the PSD boundary values to satisfy [f_min, f_max].\n",
    "    lower = int(f_min / delta_f)\n",
    "    psd[:lower] = psd[lower]\n",
    "    psd[-1:] = psd[-2]\n",
    "\n",
    "    return psd\n",
    "\n",
    "# get_psd = psd_dict['H1'].get(1 // delta_f, generate_psd(ifo, delta_f, f_max, f_min, event_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_whitened_waveform(\n",
    "    sample: Dict[str, float],\n",
    "    inclination: bool,\n",
    "    spins: bool,\n",
    "    spins_aligned: bool,\n",
    "    domain: str='RB',\n",
    "    intrinsic_only: bool=False\n",
    "):\n",
    "    # Convert from source frame to Cartesian parameters; Optional parameters have default values\n",
    "    mass_1 = sample['mass_1']\n",
    "    mass_2 = sample['mass_2']\n",
    "    phase = sample['phase']\n",
    "    coalesce_time = sample['time']\n",
    "    distance = sample['distance']\n",
    "    ra = sample['ra']\n",
    "    dec = sample['dec']\n",
    "    \n",
    "    if inclination:\n",
    "        theta_jn = sample['theta_jn']\n",
    "        psi = sample['psi']\n",
    "    else:\n",
    "        theta_jn = 0.0\n",
    "        psi = 0.0\n",
    "\n",
    "    if spins:\n",
    "        if spins_aligned:\n",
    "            spin_1x, spin_1y, spin_1z = 0., 0., sample['chi_1']\n",
    "            spin_2x, spin_2y, spin_2z = 0., 0., sample['chi_2']\n",
    "            iota = theta_jn\n",
    "        else:\n",
    "            a_1, a_2 = sample['a_1'], sample['a_2']\n",
    "            tilt_1, tilt_2 = sample['tilt_1'], sample['tilt_2']\n",
    "            phi_jl, phi_12 = sample['phi_jl'], sample['phi_12']\n",
    "\n",
    "            # use bilby/LAL to simulate an inspiral given intrinsic parameters\n",
    "            (iota, spin_1x, spin_1y, spin_1z, spin_2x, spin_2y, spin_2z) = source_frame_to_radiation(\n",
    "                theta_jn, phi_jl, tilt_1, tilt_2, phi_12, a_1, a_2, mass_1, mass_2, f_ref, phase\n",
    "            )\n",
    "    else:\n",
    "        spin_1x = 0.0\n",
    "        spin_1y = 0.0\n",
    "        spin_1z = 0.0\n",
    "        spin_2x = 0.0\n",
    "        spin_2y = 0.0\n",
    "        spin_2z = 0.0\n",
    "        iota = theta_jn\n",
    "\n",
    "    if domain == 'TD':\n",
    "        # \"Start with a TD waveform generated from pycbc. If the\n",
    "        # approximant is in FD, then this suitably tapers the low\n",
    "        # frequencies in order to have a finite-length TD waveform\n",
    "        # without wraparound effects. If we started with an FD\n",
    "        # waveform, then we would have to do these manipulations\n",
    "        # ourselves\" -- Stephen Green.\n",
    "\n",
    "        # Make sure f_min is low enough\n",
    "        if (\n",
    "            time_duration > get_waveform_filter_length_in_time(\n",
    "                mass1=mass_1, mass2=mass_2,\n",
    "                spin1x=spin_1x, spin2x=spin_2x,\n",
    "                spin1y=spin_1y, spin2y=spin_2y,\n",
    "                spin1z=spin_1z, spin2z=spin_2z,\n",
    "                inclination=iota,\n",
    "                f_lower=f_min,\n",
    "                f_ref=f_ref,\n",
    "                approximant=approximant\n",
    "            )\n",
    "        ):\n",
    "            print('Warning: f_min not low enough for given waveform duration')\n",
    "\n",
    "        hp_TD, hc_TD = get_td_waveform(\n",
    "            mass1=mass_1, mass2=mass_2,\n",
    "            spin1x=spin_1x, spin2x=spin_2x,\n",
    "            spin1y=spin_1y, spin2y=spin_2y,\n",
    "            spin1z=spin_1z, spin2z=spin_2z,\n",
    "            distance=distance,\n",
    "            coa_phase=phase,\n",
    "            inclination=iota,  # CHECK THIS!!!\n",
    "            delta_t=delta_t,\n",
    "            f_lower=f_min,\n",
    "            f_ref=f_ref,\n",
    "            approximant=approximant\n",
    "        )\n",
    "        hp = hp_TD.to_frequencyseries()\n",
    "        hc = hc_TD.to_frequencyseries()\n",
    "\n",
    "    elif domain in ('FD', 'RB'):\n",
    "        # LAL refers to approximants by an index \n",
    "        if is_fd_waveform(approximant):  # bool(SimInspiralImplementedFDApproximants(GetApproximantFromString(approximant)))\n",
    "            # Use the pycbc waveform generator; change this later (says Author)\n",
    "            # returns plus and cross phases of the waveform in frequency domain\n",
    "            hp, hc = get_fd_waveform(\n",
    "                mass1=mass_1, mass2=mass_2,\n",
    "                spin1x=spin_1x, spin2x=spin_2x,\n",
    "                spin1y=spin_1y, spin2y=spin_2y,\n",
    "                spin1z=spin_1z, spin2z=spin_2z,\n",
    "                distance=distance,\n",
    "                coa_phase=phase,\n",
    "                inclination=iota,\n",
    "                f_lower=f_min,\n",
    "                f_final=f_max,\n",
    "                delta_f=delta_f,\n",
    "                f_ref=f_ref,\n",
    "                approximant=approximant,\n",
    "            )\n",
    "        else:\n",
    "            # \"Use SimInspiralFD. This converts automatically\n",
    "            # from the TD to FD waveform, but it requires a timeshift to be\n",
    "            # applied. Approach mimics bilby treatment.\" - Stephen Green\n",
    "\n",
    "            # Require SI units\n",
    "            mass_1_SI = mass_1 * MSUN_SI\n",
    "            mass_2_SI = mass_2 * MSUN_SI\n",
    "            distance_SI = distance * PC_SI * 1e6\n",
    "\n",
    "            lal_approximant = GetApproximantFromString(approximant)\n",
    "\n",
    "            h_p, h_c = SimInspiralFD(\n",
    "                mass_1_SI, mass_2_SI,\n",
    "                spin_1x, spin_1y, spin_1z,\n",
    "                spin_2x, spin_2y, spin_2z,\n",
    "                distance_SI, iota, phase,\n",
    "                0.0, 0.0, 0.0,  # should have keyword args here?\n",
    "                delta_f, f_min, f_max,\n",
    "                f_ref, None,\n",
    "                lal_approximant,\n",
    "            )\n",
    "\n",
    "            # If f_max/delta_f is not a power of 2, SimInspiralFD increases f_max\n",
    "            # to make this a power of 2. Take only components running up to f_max.\n",
    "            hp = np.zeros_like(sample_frequencies, dtype=np.complex)\n",
    "            hc = np.zeros_like(sample_frequencies, dtype=np.complex)\n",
    "            hp[:] = h_p.data.data[:len(hp)]\n",
    "            hc[:] = h_c.data.data[:len(hp)]\n",
    "\n",
    "            # Zero the strain for frequencies below f_min\n",
    "            hp *= frequency_mask.numpy()\n",
    "            hc *= frequency_mask.numpy()\n",
    "\n",
    "            # SimInspiralFD sets the merger time so the waveform can be\n",
    "            # transformed to TD without wrapping the end of the waveform to\n",
    "            # the beginning. Bring the time of coalescence to 0.\n",
    "            dt = 1. / delta_f + (h_p.epoch.gpsSeconds + h_p.epoch.gpsNanoSeconds * 1e-9)\n",
    "            hp *= np.exp(- 1j * 2 * np.pi * dt * sample_frequencies)\n",
    "            hc *= np.exp(- 1j * 2 * np.pi * dt * sample_frequencies)\n",
    "\n",
    "            # Convert to pycbc frequencyseries. Later, get rid of pycbc functions.\n",
    "            hp = FrequencySeries(hp, delta_f=delta_f, epoch=-time_duration)\n",
    "            hc = FrequencySeries(hc, delta_f=delta_f, epoch=-time_duration)\n",
    "\n",
    "    if intrinsic_only:\n",
    "        # Whiten with reference noise PSD and return hp, hc\n",
    "        hp = hp / (_get_psd('H1', psd, hp.delta_f, f_max, f_min_psd, event_dir) ** 0.5)\n",
    "        hc = hc / (_get_psd('H1', psd, hc.delta_f, f_max, f_min_psd, event_dir) ** 0.5)\n",
    "#         hp = hp / (psd['H1'].get(1 // delta_f, generate_psd('H1', hp.delta_f, f_max, f_min_psd, event_dir)) ** 0.5)\n",
    "#         hc = hc / (psd['H1'].get(1 // delta_f, generate_psd('H1', hc.delta_f, f_max, f_min_psd, event_dir)) ** 0.5)\n",
    "    \n",
    "        # Convert to TD if necessary, ensure correct length\n",
    "        if domain == 'TD':\n",
    "            hp = hp.to_timeseries().time_slice(-time_duration, 0.0)\n",
    "            hc = hc.to_timeseries().time_slice(-time_duration, 0.0)\n",
    "\n",
    "        out = (hp.data.astype(np.complex64), hc.data.astype(np.complex64))\n",
    "\n",
    "    else:\n",
    "        # Project waveform onto detectors\n",
    "        h_d_dict = {}\n",
    "        for ifo, detector in detectors.items():\n",
    "\n",
    "            # Project onto antenna pattern\n",
    "            fp, fc = detector.antenna_pattern(ra, dec, psi, ref_time)  # fp and fc are plus and cross polarisations\n",
    "            \n",
    "            # Apply time delay relative to Earth center\n",
    "            dt = detector.time_delay_from_earth_center(ra, dec, ref_time)  # should ref_time be coalesce_time?\n",
    "            time_d = coalesce_time + dt\n",
    "            \n",
    "            # transform each plus/cross phase according to antenna pattern function\n",
    "            h_d = fp * hp + fc * hc  \n",
    "            \n",
    "            # Author's Notes: Merger is currently at time 0. Shift it.\n",
    "            # time_shift = - (self.time_duration - time_d)  # NOT SURE IF THIS LINE IS RIGHT / NEEDED. COMMENTED.\n",
    "            time_shift = time_d\n",
    "            \n",
    "            h_d = h_d.cyclic_time_shift(time_shift)\n",
    "            h_d.start_time = h_d.start_time + time_shift\n",
    "\n",
    "            # whiten\n",
    "#             h_d = h_d / (_get_psd(ifo, psd, h_d.delta_f, f_max, f_min_psd, event_dir) ** 0.5)\n",
    "            h_d = h_d / (psd[ifo].get(1 // delta_f, generate_psd(ifo, h_d.delta_f, f_max, f_min_psd, event_dir)) ** 0.5)\n",
    "\n",
    "            # Convert to TD if necessary, and ensure waveform is of correct length\n",
    "            if domain == 'TD':\n",
    "                h_d = h_d.to_timeseries().time_slice( -time_duration, 0.0)\n",
    "\n",
    "            h_d_dict[ifo] = h_d.data\n",
    "\n",
    "        out = np.stack([val.astype(np.complex64) for val in h_d_dict.values()])\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformGenerator:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spins: bool=True,\n",
    "        inclination: bool=True,\n",
    "        spins_aligned: bool=True,\n",
    "        mass_ratio: bool=False,\n",
    "        detectors: List[str]=['H1', 'L1', 'V1'],\n",
    "        domain: str='TD',\n",
    "        extrinsic_at_train: bool=False,\n",
    "        num_workers: int=1,\n",
    "    ):\n",
    "        \"Contains a database of waveforms from which to train a model.\"\n",
    "        # multiprocessing\n",
    "        assert num_workers <= multiprocessing.cpu_count()\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        # parameterisation\n",
    "        self.spins = spins\n",
    "        self.spins_aligned = spins_aligned\n",
    "        self.inclination = inclination\n",
    "        self.mass_ratio = mass_ratio\n",
    "        self.domain = domain\n",
    "        \n",
    "        # whether to apply extrinsic parameters at train or data prep time\n",
    "        self.extrinsic_at_train = extrinsic_at_train\n",
    "        self.extrinsic_params = ['time', 'distance', 'psi', 'ra', 'dec']\n",
    "        \n",
    "        # Set up indices for parameters\n",
    "        self.parameters = generate_ordered_parameters(spins, spins_aligned, inclination, mass_ratio)\n",
    "        self.param_idx = {param: i for i, param in enumerate(self.parameters)}\n",
    "        self.nparams = len(self.parameters)\n",
    "        \n",
    "        # Default prior ranges\n",
    "        self.priors = dict(\n",
    "            mass_1=[10.0, 80.0],  # solar masses\n",
    "            mass_2=[10.0, 80.0],\n",
    "            M=[25.0, 100.0],\n",
    "            q=[0.125, 1.0],\n",
    "            phase=[0.0, 2*math.pi],\n",
    "            time=[-0.1, 0.1],  # seconds\n",
    "            distance=[100.0, 4000.0],  # Mpc\n",
    "            chi_1=[-1.0, 1.0],\n",
    "            chi_2=[-1.0, 1.0],\n",
    "            a_1=[0.0, 0.99],\n",
    "            a_2=[0.0, 0.99],\n",
    "            tilt_1=[0.0, math.pi],\n",
    "            tilt_2=[0.0, math.pi],\n",
    "            phi_12=[0.0, 2*math.pi],\n",
    "            phi_jl=[0.0, 2*math.pi],\n",
    "            theta_jn=[0.0, math.pi],\n",
    "            psi=[0.0, math.pi],\n",
    "            ra=[0.0, 2*math.pi],\n",
    "            dec=[-math.pi/2.0, math.pi/2.0]\n",
    "        )\n",
    "        \n",
    "        self.priors = {key: value for key, value in self.priors.items() if key in self.parameters}\n",
    "        \n",
    "        self.latex = dict(\n",
    "            mass_1=r'$m_1$',\n",
    "            mass_2=r'$m_2$',\n",
    "            M=r'$M$',\n",
    "            q=r'$q$',\n",
    "            phase=r'$\\phi_c$',\n",
    "            time=r'$t_c$',\n",
    "            distance=r'$d_L$',\n",
    "            chi_1=r'$\\chi_1$',\n",
    "            chi_2=r'$\\chi_2$',\n",
    "            a_1=r'$a_1$',\n",
    "            a_2=r'$a_2$',\n",
    "            tilt_1=r'$t_1$',\n",
    "            tilt_2=r'$t_2$',\n",
    "            phi_12=r'$\\phi_{12}$',\n",
    "            phi_jl=r'$\\phi_{jl}$',\n",
    "            theta_jn=r'$\\theta_{JN}$',\n",
    "            psi=r'$\\psi$',\n",
    "            ra=r'$\\alpha$',\n",
    "            dec=r'$\\delta$'\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def parameter_labels(self):\n",
    "        labels = []\n",
    "        for param in self.param_idx.keys():\n",
    "            labels.append(self.latex[param])\n",
    "        return labels\n",
    "    \n",
    "#     def _sample_numpy_prior(self, n: int) -> Dict[str, List[float]]:\n",
    "        #\n",
    "   \n",
    "    def _sample_prior(self, n):\n",
    "        # create dictionary of prior ranges and instantiate them as torch tensors\n",
    "        bounds = {\n",
    "            param: torch.tensor(self.priors[param], dtype=torch.float64) # device=device\n",
    "            for param in self.parameters\n",
    "        }\n",
    "\n",
    "        # transform prior domain in order to sample form uniform (must be sorted as [low, high])\n",
    "        bounds = {\n",
    "            param: (\n",
    "                value.pow(3).sort().values if param == 'distance'\n",
    "                else value.sin().sort().values if param == 'dec'\n",
    "                else value.cos().sort().values if param in ['theta_jn', 'tilt_1', 'tilt_2']\n",
    "                else value.sort().values\n",
    "            ) for param, value in bounds.items()\n",
    "        }\n",
    "\n",
    "        # create a torch.distributions.uniform.Uniform object for each parameter\n",
    "        uniform_priors = { param: Uniform(*value, validate_args=True) for param, value in bounds.items()}\n",
    "\n",
    "        # sample from uniform distributions\n",
    "        samples = {parameter: distribution.sample([n]) for parameter, distribution in uniform_priors.items()}\n",
    "\n",
    "        # undo uniformity transformations\n",
    "        samples = {\n",
    "            param: (\n",
    "                value.pow(1/3) if param == 'distance'\n",
    "                else value.arcsin() if param == 'dec'\n",
    "                else value.arccos() if param in ['theta_jn', 'tilt_1', 'tilt_2']\n",
    "                else value\n",
    "            ) for param, value in samples.items()\n",
    "        }\n",
    "\n",
    "        # handle mass and mass ratios\n",
    "        if ('M' in samples.keys()) and ('q' in samples.keys()):\n",
    "            # reparameterise M and Q to be component masses (unordered)\n",
    "            samples['mass_1'] = samples['M'] * samples['q']\n",
    "            samples['mass_2'] = samples['M'] * (1 - samples['q'])\n",
    "\n",
    "            # recreate samples dictinoary without M and Q (and inserts mass_1 and mass_2 at the front)\n",
    "            samples = {\n",
    "                'mass_1': samples['M'] * samples['q'],\n",
    "                'mass_2': samples['M'] * (1 - samples['q']),\n",
    "                **{key: val for key, val in samples.items() if key not in ('M','q')}\n",
    "            }\n",
    "\n",
    "        # uphold constraint that mass_1 >= mass_2 by sorting along the concatenated dimension then splitting\n",
    "        # warning: this approach may have some unintended consequences regarding the prior bounds of m1 and m2\n",
    "        samples['mass_1'], samples['mass_2'] = torch.stack([samples['mass_1'], samples['mass_2']]).sort(dim=0).values\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = WaveformGenerator(\n",
    "    inclination=False,\n",
    "    spins_aligned=True,\n",
    "    mass_ratio=False,\n",
    "    extrinsic_at_train=False,\n",
    "    domain='RB',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waveform Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int=512,\n",
    "        data_dir: Union[Path, str]=None,\n",
    "        detectors: List[str]=['H1','L1','V1'],\n",
    "        domain: str='RB',  # only configured for RB basis\n",
    "        extrinsic_at_train: bool=False,\n",
    "    ):\n",
    "        \"\"\"A PyTorch LightningDataModule used to manage waveform datasets.\"\"\"\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.detectors = {ifo: Detector(ifo) for ifo in detectors}\n",
    "        \n",
    "        self.basis = None\n",
    "        \n",
    "    def prepare_data(self, load: bool=True):\n",
    "        # only called on one GPU/TPU in distributed training (the \"head\" node?)\n",
    "        # prepared waveform dataset takes n (a long time) hours and is 8.5GB - how to handle this\n",
    "        assert data_dir.exists(), f'Provided data_dir {data_dir} is not a valid directory.'\n",
    "        \n",
    "#         if self.domain == 'RB' and self.basis is None:\n",
    "#             self.generate_reduced_basis()\n",
    "    \n",
    "    def setup(self):\n",
    "        # make assignments here (val/train/test split) - called on every process in DDP\n",
    "        pass\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "#         train_split = DataSet(...)\n",
    "#         return DataLoader(train_split)\n",
    "        pass\n",
    "\n",
    "    def val_dataloader(self):\n",
    "#         val_split = DataSet(...)\n",
    "#         return DataLoader(val_split)\n",
    "        pass\n",
    "\n",
    "    def test_dataloader(self):\n",
    "#         test_split = DataSet(...)\n",
    "#         return DataLoader(test_split)\n",
    "        pass\n",
    "\n",
    "    def teardown(self):\n",
    "        # clean up after fit or test - called on every process in DDP\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximant = 'IMRPhenomPv2' # LAL refers to approximants by idx from GetApproximantFromString(approximant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (and overwrite) data\n",
    "with open(Path('data/events/GW150914') / 'event_info.json', 'r') as f:\n",
    "    event_info = json.load(f)\n",
    "    \n",
    "# waveform settings\n",
    "with open(Path('waveforms') / 'GW150914' / 'settings.json', 'r') as f:\n",
    "    settings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psd_names = dict(\n",
    "#     H1='aLIGODesignSensitivityP1200087',\n",
    "#     L1='aLIGODesignSensitivityP1200087',\n",
    "#     V1='AdVDesignSensitivityP1200087',\n",
    "#     ref='aLIGODesignSensitivityP1200087'\n",
    "# )\n",
    "\n",
    "# psd_dict = dict(\n",
    "#     H1={},\n",
    "#     L1={},\n",
    "#     V1={},\n",
    "#     ref={}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data (event and data store)\n",
    "event = 'GW150914'  # gravitational wave event label\n",
    "data_dir = Path('data')  # data store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directories\n",
    "events_dir = data_dir / 'events'  # gravitational wave events\n",
    "waveforms_dir = data_dir / 'waveforms'  # generated waveforms\n",
    "event_dir = events_dir / event  # specific event data\n",
    "\n",
    "# Load event info\n",
    "with open(event_dir / 'event_info.json', 'r') as f:\n",
    "    event_info = json.load(f)\n",
    "\n",
    "if 'f_min_psd' not in event_info:\n",
    "    event_info['f_min_psd'] = event_info['f_min']\n",
    "\n",
    "# rename keys with pointers - need to unify names between saving files and attributes\n",
    "event_info['duration'] = event_info['T']\n",
    "event_info['ref_time'] = event_info['t_event']\n",
    "\n",
    "detectors = {ifo: Detector(ifo) for ifo in event_info['detectors']}\n",
    "\n",
    "psd = {}\n",
    "psd_names = {}\n",
    "for ifo in detectors:\n",
    "    psd[ifo] = {}\n",
    "    psd_names[ifo] = f'PSD_{ifo}'\n",
    "psd['ref'] = {}\n",
    "psd_names['ref'] = psd_names['H1']  # this is hardcoded by author -- reference ifo must be Hanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we want these as entries in a dictionary? standalone variables? computed on the fly?\n",
    "event_info['sampling_rate'] = 2*event_info['f_max']\n",
    "event_info['delta_t'] = 1.0 / event_info['sampling_rate']\n",
    "event_info['delta_f'] = (1.0 / event_info['duration'])\n",
    "event_info['Nf'] = int(event_info['f_max'] / event_info['delta_f']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psd_name=f'PSD_H1'\n",
    "# delta_f=event_info['delta_f']\n",
    "# f_min=event_info['f_min_psd']\n",
    "# f_max=event_info['f_max']\n",
    "# psd_length = int(f_max / delta_f) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>latex</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>transform</th>\n",
       "      <th>inverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mass_1</td>\n",
       "      <td>$m_1$</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mass_2</td>\n",
       "      <td>$m_2$</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>$M$</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q</td>\n",
       "      <td>$q$</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phase</td>\n",
       "      <td>$\\phi_c$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.283185</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>$t_c$</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>distance</td>\n",
       "      <td>$d_L$</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>pow(3)</td>\n",
       "      <td>pow(1/3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chi_1</td>\n",
       "      <td>$\\chi_1$</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chi_2</td>\n",
       "      <td>$\\chi_2$</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a_1</td>\n",
       "      <td>$a_1$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a_2</td>\n",
       "      <td>$a_2$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tilt_1</td>\n",
       "      <td>$t_1$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>cos</td>\n",
       "      <td>arccos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tilt_2</td>\n",
       "      <td>$t_2$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>cos</td>\n",
       "      <td>arccos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phi_12</td>\n",
       "      <td>$\\phi_{12}$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.283185</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>phi_jl</td>\n",
       "      <td>$\\phi_{jl}$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.283185</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>theta_jn</td>\n",
       "      <td>$\\theta_{JN}$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>cos</td>\n",
       "      <td>arccos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>psi</td>\n",
       "      <td>$\\psi$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ra</td>\n",
       "      <td>$\\alpha$</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.283185</td>\n",
       "      <td>identity</td>\n",
       "      <td>identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dec</td>\n",
       "      <td>$\\delta$</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>sin</td>\n",
       "      <td>arcsin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name          latex       lower        upper transform   inverse\n",
       "0     mass_1          $m_1$   10.000000    80.000000  identity  identity\n",
       "1     mass_2          $m_2$   10.000000    80.000000  identity  identity\n",
       "2          M            $M$   25.000000   100.000000  identity  identity\n",
       "3          q            $q$    0.125000     1.000000  identity  identity\n",
       "4      phase       $\\phi_c$    0.000000     6.283185  identity  identity\n",
       "5       time          $t_c$   -0.100000     0.100000  identity  identity\n",
       "6   distance          $d_L$  100.000000  1000.000000    pow(3)  pow(1/3)\n",
       "7      chi_1       $\\chi_1$   -1.000000     1.000000  identity  identity\n",
       "8      chi_2       $\\chi_2$   -1.000000     1.000000  identity  identity\n",
       "9        a_1          $a_1$    0.000000     0.880000  identity  identity\n",
       "10       a_2          $a_2$    0.000000     0.880000  identity  identity\n",
       "11    tilt_1          $t_1$    0.000000     3.141593       cos    arccos\n",
       "12    tilt_2          $t_2$    0.000000     3.141593       cos    arccos\n",
       "13    phi_12    $\\phi_{12}$    0.000000     6.283185  identity  identity\n",
       "14    phi_jl    $\\phi_{jl}$    0.000000     6.283185  identity  identity\n",
       "15  theta_jn  $\\theta_{JN}$    0.000000     3.141593       cos    arccos\n",
       "16       psi         $\\psi$    0.000000     3.141593  identity  identity\n",
       "17        ra       $\\alpha$    0.000000     6.283185  identity  identity\n",
       "18       dec       $\\delta$   -1.570796     1.570796       sin    arcsin"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveforms = WaveformGenerator(inclination=False, spins_aligned=True, mass_ratio=False, domain='RB', extrinsic_at_train=False)\n",
    "\n",
    "# manually specified by author\n",
    "waveforms.priors['distance'] = [100.0, 1000.0]\n",
    "waveforms.priors['a_1'][1] = 0.88\n",
    "waveforms.priors['a_2'][1] = 0.88\n",
    "\n",
    "prior_df = pd.DataFrame([\n",
    "    {'name': key, 'lower': value[0], 'upper': value[1]}\n",
    "    for key, value in waveforms.priors.items()\n",
    "])\n",
    "\n",
    "# prior_df.insert(1, 'distribution', [\n",
    "#     'cos' if key in ('theta_jn', 'tilt_1', 'tilt_2')\n",
    "#     else 'sin' if key == 'dec'\n",
    "#     else 'uniform'\n",
    "#     for key in priors.name\n",
    "# ])\n",
    "\n",
    "prior_df.insert(1, 'latex', list(waveforms.latex.values()))\n",
    "\n",
    "prior_df['transform'] = [\n",
    "    'pow(3)' if param == 'distance'\n",
    "    else 'sin' if param == 'dec'\n",
    "    else 'cos' if param in ['theta_jn', 'tilt_1', 'tilt_2']\n",
    "    else 'identity'\n",
    "    for param in prior_df.name\n",
    "]\n",
    "\n",
    "prior_df['inverse'] = [\n",
    "    'pow(1/3)' if param == 'distance'\n",
    "    else 'arcsin' if param == 'dec'\n",
    "    else 'arccos' if param in ['theta_jn', 'tilt_1', 'tilt_2']\n",
    "    else 'identity'\n",
    "    for param in prior_df.name\n",
    "]\n",
    "\n",
    "prior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_event(event_dir: Union[Path, str]):\n",
    "    event_dir = Path(event_dir)\n",
    "\n",
    "    # Load event info\n",
    "    with open(event_dir / 'event_info.json', 'r') as f:\n",
    "        event_info = json.load(f)\n",
    "        event_info['f_min_psd'] = event_info['f_min_psd'] or event_info['f_min']\n",
    "        \n",
    "        self.event = event_info['event']\n",
    "        self.f_min = event_info['f_min']\n",
    "        self.f_min_psd = event_info['f_min']  # copy f_min\n",
    "        self.f_max = event_info['f_max']\n",
    "        self.time_duration = event_info['T']\n",
    "        self.ref_time = event_info['t_event']\n",
    "        self.window_factor = event_info['window_factor']\n",
    "        ifo_list = event_info['detectors']\n",
    "\n",
    "    # Initialize detectors\n",
    "    self.init_detectors(detectors)\n",
    "    \n",
    "    detectors = {ifo: Detector(ifo) for ifo in ifo_list}\n",
    "    detectors['ref'] = detectors['H1']  # author uses this \"ref\" detector and is hard coded as H1\n",
    "\n",
    "    # Set up PSD\n",
    "    self.psd = {}\n",
    "    self.psd_names = {}\n",
    "    for ifo in detectors:\n",
    "        self.psd[ifo] = {}\n",
    "        self.psd_names[ifo] = 'PSD_{}'.format(ifo)\n",
    "    self.psd['ref'] = {}\n",
    "    self.psd_names['ref'] = self.psd_names['H1']\n",
    "    \n",
    "try:\n",
    "    event = settings['event']\n",
    "    event_dir = settings['event_dir']\n",
    "    if event_dir != 'None':\n",
    "        event_dir = Path(event_dir)\n",
    "    load_event(event_dir)\n",
    "except:\n",
    "    event = None\n",
    "    event_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load event info (default settings)\n",
    "# time_duration = 4.0  # seconds\n",
    "# f_min = 8.0 if waveforms.domain == 'TD' else 20.0  # Hz\n",
    "# ifo_list = ['H1','L1','V1']\n",
    "# f_ref = 20.0  # frequency at which source frame spin parameters are defined\n",
    "    \n",
    "# why is this data split across two JSONs like this? data integrity??\n",
    "time_duration = event_info['T']\n",
    "f_max = event_info['f_max']\n",
    "\n",
    "event = settings['event']\n",
    "event_dir = Path(settings['event_dir'])\n",
    "\n",
    "ifo_list = settings['detectors']\n",
    "f_min = settings['f_min']\n",
    "f_min_psd = settings['f_min_psd']\n",
    "f_ref = settings['f_ref']\n",
    "ref_time = settings['ref_time']\n",
    "\n",
    "sampling_rate = 2*f_max\n",
    "delta_t = 1.0 / sampling_rate\n",
    "delta_f = (1.0 / time_duration)\n",
    "Nf = int(f_max / delta_f) + 1\n",
    "\n",
    "# methods used with lru_cache\n",
    "sample_frequencies = torch.linspace(0.0, f_max, steps=Nf)\n",
    "frequency_mask = sample_frequencies >= f_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_reduced_basis(self, n_train=10000, n_test=10000):\n",
    "n_train=50000 # 100000 # #228885 #2000000 #50000\n",
    "n_test=1000\n",
    "# detectors = {ifo: Detector(ifo) for ifo in ifo_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {key: value.numpy() for key, value in waveforms._sample_prior(n_train).items()}\n",
    "\n",
    "# To generate reduced basis, fix all waveforms to same fiducial distance.  need justification here imo\n",
    "data['distance'] = np.ones_like(data['distance'])*settings['fiducial_params']['distance']\n",
    "\n",
    "# convert into 'records' format as list of dictionary with each key a parameter\n",
    "samples = [\n",
    "    {key: value for key, value in zip(data.keys(), sample)}\n",
    "    for sample in np.array(tuple(data.values())).T\n",
    "]\n",
    "\n",
    "# df = pd.DataFrame(samples)\n",
    "# fig = px.density_contour(df, x='mass_1', y='mass_2', marginal_x='histogram', marginal_y='histogram')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "\n",
    "def parallel_process(function, array, n_jobs: int=16, use_kwargs: bool=False, front_num: int=3):\n",
    "    \"\"\"\n",
    "        A parallel version of the map function with a progress bar. \n",
    "\n",
    "        Args:\n",
    "            array (array-like): An array to iterate over.\n",
    "            function (function): A python function to apply to the elements of array\n",
    "            n_jobs (int, default=16): The number of cores to use\n",
    "            use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of \n",
    "                keyword arguments to function \n",
    "            front_num (int, default=3): The number of iterations to run serially before kicking off the parallel job. \n",
    "                Useful for catching bugs\n",
    "        Returns:\n",
    "            [function(array[0]), function(array[1]), ...]\n",
    "    \"\"\"\n",
    "    #We run the first few iterations serially to catch bugs\n",
    "    if front_num > 0:\n",
    "        front = [function(**a) if use_kwargs else function(a) for a in array[:front_num]]\n",
    "        \n",
    "    #If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.\n",
    "    if n_jobs==1:\n",
    "        return front + [function(**a) if use_kwargs else function(a) for a in tqdm(array[front_num:])]\n",
    "    \n",
    "    #Assemble the workers\n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as pool:\n",
    "        #Pass the elements of array into function\n",
    "        if use_kwargs:\n",
    "            futures = [pool.submit(function, **a) for a in array[front_num:]]\n",
    "        else:\n",
    "            futures = [pool.submit(function, a) for a in array[front_num:]]\n",
    "            \n",
    "        kwargs = {\n",
    "            'total': len(futures),\n",
    "            'unit': 'it',\n",
    "            'unit_scale': True,\n",
    "            'leave': True\n",
    "        }\n",
    "        \n",
    "        #Print out the progress as tasks complete\n",
    "        for f in tqdm(as_completed(futures), **kwargs):\n",
    "            pass\n",
    "        \n",
    "    out = []\n",
    "    \n",
    "    #Get the results from the futures. \n",
    "    for i, future in tqdm(enumerate(futures)):\n",
    "        try:\n",
    "            out.append(future.result())\n",
    "        except Exception as e:\n",
    "            out.append(e)\n",
    "            \n",
    "    return front + out\n",
    "\n",
    "# results = parallel_process(\n",
    "#     function=generate_waveforms,\n",
    "#     array=samples,\n",
    "#     use_kwargs=False,\n",
    "#     n_jobs=num_workers,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waveform dataset configuration:\n",
      "inclination: False\n",
      "spins: True\n",
      "spins_aligned: True\n",
      "domain: RB\n",
      "num_workers: 23\n"
     ]
    }
   ],
   "source": [
    "# setup \n",
    "num_workers = multiprocessing.cpu_count()-1\n",
    "# num_workers = 2\n",
    "\n",
    "generate_waveforms = partial(\n",
    "    generate_whitened_waveform,\n",
    "    inclination=waveforms.inclination,\n",
    "    spins=waveforms.spins,\n",
    "    spins_aligned=waveforms.spins_aligned,\n",
    "    domain=waveforms.domain,\n",
    "    intrinsic_only=True,\n",
    ")\n",
    "\n",
    "print('waveform dataset configuration:')\n",
    "print(f'inclination: {waveforms.inclination}')\n",
    "print(f'spins: {waveforms.spins}')\n",
    "print(f'spins_aligned: {waveforms.spins_aligned}')\n",
    "print(f'domain: {waveforms.domain}')\n",
    "print(f'num_workers: {num_workers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_waveforms = {\n",
    "    ifo: np.empty((len(samples), Nf), dtype=np.complex64)\n",
    "    for ifo in detectors.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating whitened waveforms on 23 processes:   3%|         | 1725/50000 [00:45<21:21, 37.67it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-125bb22432e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     training_array = np.concatenate(list(tqdm(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_waveforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \"\"\"\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-125bb22432e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# process data to be used for generating reduced basis via SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     training_array = np.concatenate(list(tqdm(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_waveforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/concurrent/futures/process.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread_wakeup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# objects that use file descriptors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astro/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# process data to be used for generating reduced basis via SVD\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    training_array = np.concatenate(list(tqdm(\n",
    "        executor.map(generate_waveforms, samples, chunksize=75),\n",
    "        total=len(samples),\n",
    "        desc=f'Generating whitened waveforms on {num_workers} processes',\n",
    "    )))\n",
    "    \n",
    "for key in parameters:\n",
    "    parameters[key] = parameters[key].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nrb = 200  # hardcoded number of reduced basis elements as per author\n",
    "U, s, Vh = randomized_svd(training_array, Nrb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 34s  0 ns per loop (mean  std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "Nrb = 200  # hardcoded number of reduced basis elements as per author\n",
    "U, s, Vh = randomized_svd(training_array, Nrb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8min 47s  0 ns per loop (mean  std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "U, s, Vh = scipy.linalg.svd(training_array, full_matrices=False)\n",
    "# V = Vh.T.conj()\n",
    "\n",
    "# if (n == 0) or (n > len(V)):\n",
    "#     self.V = V\n",
    "#     self.Vh = Vh\n",
    "# else:\n",
    "#     self.V = V[:, :n]\n",
    "#     self.Vh = Vh[:n, :]\n",
    "\n",
    "# self.n = len(self.Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 8193)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mass_1': array([10.947892, 15.541207, 63.409836, ..., 30.754145, 32.50648 ,\n",
       "        33.672577], dtype=float32),\n",
       " 'mass_2': array([36.354824, 79.62963 , 68.202065, ..., 38.730396, 55.61173 ,\n",
       "        63.18906 ], dtype=float32),\n",
       " 'phase': array([3.5613995, 6.25151  , 3.7510014, ..., 4.346566 , 1.8440422,\n",
       "        5.7286015], dtype=float32),\n",
       " 'time': array([-0.09021521,  0.08645985, -0.0951781 , ..., -0.00942908,\n",
       "         0.01464454, -0.0817539 ], dtype=float32),\n",
       " 'distance': array([1000., 1000., 1000., ..., 1000., 1000., 1000.], dtype=float32),\n",
       " 'chi_1': array([-0.81193763, -0.4034527 ,  0.67301285, ...,  0.18957698,\n",
       "         0.6633359 ,  0.06395798], dtype=float32),\n",
       " 'chi_2': array([ 0.292476  , -0.04284127, -0.32827464, ..., -0.9876351 ,\n",
       "         0.7571041 , -0.14255877], dtype=float32),\n",
       " 'ra': array([1.2162216 , 0.20546114, 5.0787644 , ..., 1.6396039 , 1.1205654 ,\n",
       "        0.36769477], dtype=float32),\n",
       " 'dec': array([-0.5135797 ,  0.706079  ,  0.2885482 , ..., -1.1187202 ,\n",
       "         0.2254409 ,  0.23163974], dtype=float32)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.1088"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32772000000*1e-9*10/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26217600000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.2176"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26217600000*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8193,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['H1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating whitened waveforms utilising 23 workers (chunksize=50): 100%|| 50000/50000 [00:25<00:00, 1975.63it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=60): 100%|| 50000/50000 [00:26<00:00, 1893.70it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=70): 100%|| 50000/50000 [00:22<00:00, 2206.05it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=80): 100%|| 50000/50000 [00:22<00:00, 2204.33it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=90): 100%|| 50000/50000 [00:23<00:00, 2142.19it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=100): 100%|| 50000/50000 [00:23<00:00, 2170.43it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=110): 100%|| 50000/50000 [00:23<00:00, 2120.07it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=120): 100%|| 50000/50000 [00:22<00:00, 2199.76it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=130): 100%|| 50000/50000 [00:22<00:00, 2179.86it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=140): 100%|| 50000/50000 [00:23<00:00, 2120.75it/s]\n",
      "Generating whitened waveforms utilising 23 workers (chunksize=150): 100%|| 50000/50000 [00:23<00:00, 2155.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# chunksizes = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "# runtimes = []\n",
    "\n",
    "# with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     for chunksize in chunksizes:\n",
    "#         start = time.perf_counter()\n",
    "#         results = list(tqdm(\n",
    "#             executor.map(generate_waveforms, samples, chunksize=chunksize),\n",
    "#             total=len(samples),\n",
    "#             desc=f'Generating whitened waveforms utilising {num_workers} workers (chunksize={chunksize})',\n",
    "#         ))\n",
    "#         finish = time.perf_counter()\n",
    "#         runtimes.append(round(finish - start, 6))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in tqdm(samples):\n",
    "#     mass_1 = sample['mass_1']\n",
    "#     mass_2 = sample['mass_2']\n",
    "#     phase = sample['phase']\n",
    "#     coalesce_time = sample['time']\n",
    "#     distance = sample['distance']\n",
    "#     ra = sample['ra']\n",
    "#     dec = sample['dec']\n",
    "\n",
    "#     # Convert from source frame to Cartesian parameters; Optional parameters have default values\n",
    "#     if prior_data.inclination:\n",
    "#         theta_jn = sample['theta_jn']\n",
    "#         psi = sample['psi']\n",
    "#     else:\n",
    "#         theta_jn = 0.0\n",
    "#         psi = 0.0\n",
    "\n",
    "#     if prior_data.spins:\n",
    "#         if prior_data.spins_aligned:\n",
    "#             spin_1x, spin_1y, spin_1z = 0., 0., sample['chi_1']\n",
    "#             spin_2x, spin_2y, spin_2z = 0., 0., sample['chi_2']\n",
    "#             iota = theta_jn\n",
    "#         else:\n",
    "#             a_1, a_2 = sample['a_1'], sample['a_2']\n",
    "#             tilt_1, tilt_2 = sample['tilt_1'], sample['tilt_2']\n",
    "#             phi_jl, phi_12 = sample['phi_jl'], sample['phi_12']\n",
    "\n",
    "#             # use bilby/LAL to simulate an inspiral given intrinsic parameters\n",
    "#             (iota, spin_1x, spin_1y, spin_1z, spin_2x, spin_2y, spin_2z) = source_frame_to_radiation(\n",
    "#                 theta_jn, phi_jl, tilt_1, tilt_2, phi_12, a_1, a_2, mass_1, mass_2, f_ref, phase\n",
    "#             )\n",
    "#     else:\n",
    "#         spin_1x = 0.0\n",
    "#         spin_1y = 0.0\n",
    "#         spin_1z = 0.0\n",
    "#         spin_2x = 0.0\n",
    "#         spin_2y = 0.0\n",
    "#         spin_2z = 0.0\n",
    "#         iota = theta_jn\n",
    "        \n",
    "\n",
    "#     if prior_data.domain == 'TD':\n",
    "#         # \"Start with a TD waveform generated from pycbc. If the\n",
    "#         # approximant is in FD, then this suitably tapers the low\n",
    "#         # frequencies in order to have a finite-length TD waveform\n",
    "#         # without wraparound effects. If we started with an FD\n",
    "#         # waveform, then we would have to do these manipulations\n",
    "#         # ourselves\" -- Stephen Green.\n",
    "\n",
    "#         # Make sure f_min is low enough\n",
    "#         if (\n",
    "#             time_duration > get_waveform_filter_length_in_time(\n",
    "#                 mass1=mass_1, mass2=mass_2,\n",
    "#                 spin1x=spin_1x, spin2x=spin_2x,\n",
    "#                 spin1y=spin_1y, spin2y=spin_2y,\n",
    "#                 spin1z=spin_1z, spin2z=spin_2z,\n",
    "#                 inclination=iota,\n",
    "#                 f_lower=f_min,\n",
    "#                 f_ref=f_ref,\n",
    "#                 approximant=approximant\n",
    "#             )\n",
    "#         ):\n",
    "#             print('Warning: f_min not low enough for given waveform duration')\n",
    "\n",
    "#         hp_TD, hc_TD = get_td_waveform(\n",
    "#             mass1=mass_1, mass2=mass_2,\n",
    "#             spin1x=spin_1x, spin2x=spin_2x,\n",
    "#             spin1y=spin_1y, spin2y=spin_2y,\n",
    "#             spin1z=spin_1z, spin2z=spin_2z,\n",
    "#             distance=distance,\n",
    "#             coa_phase=phase,\n",
    "#             inclination=iota,  # CHECK THIS!!!\n",
    "#             delta_t=delta_t,\n",
    "#             f_lower=f_min,\n",
    "#             f_ref=f_ref,\n",
    "#             approximant=approximant\n",
    "#         )\n",
    "#         hp = hp_TD.to_frequencyseries()\n",
    "#         hc = hc_TD.to_frequencyseries()\n",
    "\n",
    "#     elif prior_data.domain in ('FD', 'RB'):\n",
    "#             # LAL refers to approximants by an index \n",
    "#         if is_fd_waveform(approximant):  # bool(SimInspiralImplementedFDApproximants(GetApproximantFromString(approximant)))\n",
    "#             # Use the pycbc waveform generator; change this later (says Author)\n",
    "#             # returns plus and cross phases of the waveform in frequency domain\n",
    "#             hp, hc = get_fd_waveform(\n",
    "#                 mass1=mass_1, mass2=mass_2,\n",
    "#                 spin1x=spin_1x, spin2x=spin_2x,\n",
    "#                 spin1y=spin_1y, spin2y=spin_2y,\n",
    "#                 spin1z=spin_1z, spin2z=spin_2z,\n",
    "#                 distance=distance,\n",
    "#                 coa_phase=phase,\n",
    "#                 inclination=iota,\n",
    "#                 f_lower=f_min,\n",
    "#                 f_final=f_max,\n",
    "#                 delta_f=delta_f,\n",
    "#                 f_ref=f_ref,\n",
    "#                 approximant=approximant,\n",
    "#             )\n",
    "#         else:\n",
    "#             # \"Use SimInspiralFD. This converts automatically\n",
    "#             # from the TD to FD waveform, but it requires a timeshift to be\n",
    "#             # applied. Approach mimics bilby treatment.\" - Stephen Green\n",
    "\n",
    "#             # Require SI units\n",
    "#             mass_1_SI = mass_1 * MSUN_SI\n",
    "#             mass_2_SI = mass_2 * MSUN_SI\n",
    "#             distance_SI = distance * PC_SI * 1e6\n",
    "\n",
    "#             lal_approximant = GetApproximantFromString(approximant)\n",
    "\n",
    "#             h_p, h_c = SimInspiralFD(\n",
    "#                 mass_1_SI, mass_2_SI,\n",
    "#                 spin_1x, spin_1y, spin_1z,\n",
    "#                 spin_2x, spin_2y, spin_2z,\n",
    "#                 distance_SI, iota, phase,\n",
    "#                 0.0, 0.0, 0.0,  # should have keyword args here?\n",
    "#                 delta_f, f_min, f_max,\n",
    "#                 f_ref, None,\n",
    "#                 lal_approximant,\n",
    "#             )\n",
    "\n",
    "#             # If f_max/delta_f is not a power of 2, SimInspiralFD increases f_max\n",
    "#             # to make this a power of 2. Take only components running up to f_max.\n",
    "#             hp = np.zeros_like(sample_frequencies, dtype=np.complex)\n",
    "#             hc = np.zeros_like(sample_frequencies, dtype=np.complex)\n",
    "#             hp[:] = h_p.data.data[:len(hp)]\n",
    "#             hc[:] = h_c.data.data[:len(hp)]\n",
    "\n",
    "#             # Zero the strain for frequencies below f_min\n",
    "#             hp *= frequency_mask.numpy()\n",
    "#             hc *= frequency_mask.numpy()\n",
    "\n",
    "#             # SimInspiralFD sets the merger time so the waveform can be\n",
    "#             # transformed to TD without wrapping the end of the waveform to\n",
    "#             # the beginning. Bring the time of coalescence to 0.\n",
    "#             dt = 1. / delta_f + (h_p.epoch.gpsSeconds + h_p.epoch.gpsNanoSeconds * 1e-9)\n",
    "#             hp *= np.exp(- 1j * 2 * np.pi * dt * sample_frequencies)\n",
    "#             hc *= np.exp(- 1j * 2 * np.pi * dt * sample_frequencies)\n",
    "\n",
    "#             # Convert to pycbc frequencyseries. Later, get rid of pycbc functions.\n",
    "#             hp = FrequencySeries(hp, delta_f=delta_f, epoch=-time_duration)\n",
    "#             hc = FrequencySeries(hc, delta_f=delta_f, epoch=-time_duration)\n",
    "\n",
    "#     intrinsic_only=False\n",
    "#     if intrinsic_only:  # don't have specific detector data at this point, it would seem\n",
    "#         # Whiten with reference noise PSD and return hp, hc\n",
    "#         hp = hp / (_get_psd(detectors['ref'], psd, hp.delta_f, f_max, f_min_psd, event_dir) ** 0.5)\n",
    "#         hc = hc / (_get_psd(detectors['ref'], psd, hc.delta_f, f_max, f_min_psd, event_dir) ** 0.5)\n",
    "\n",
    "#         # Convert to TD if necessary, ensure correct length\n",
    "#         if self.domain == 'TD':\n",
    "#             hp = hp.to_timeseries().time_slice(-time_duration, 0.0)\n",
    "#             hc = hc.to_timeseries().time_slice(-time_duration, 0.0)\n",
    "\n",
    "#         out = (hp.data, hc.data)\n",
    "\n",
    "#     else:\n",
    "#         # Project waveform onto detectors\n",
    "#         h_d_dict = {}\n",
    "#         for ifo, detector in detectors.items():\n",
    "\n",
    "#             # Project onto antenna pattern\n",
    "#             fp, fc = detector.antenna_pattern(ra, dec, psi, ref_time)  # fp and fc are plus and cross polarisations\n",
    "#             h_d = fp * hp + fc * hc  # transform each plus/cross phase according to antenna pattern function\n",
    "\n",
    "#             # Apply time delay relative to Earth center\n",
    "#             dt = detector.time_delay_from_earth_center(ra, dec, ref_time)  # should ref_time be coalesce_time?\n",
    "#             time_d = coalesce_time + dt\n",
    "\n",
    "#             # Author's Notes: Merger is currently at time 0. Shift it.\n",
    "#             # NOT SURE NEXT LINE IS RIGHT / NEEDED. COMMENTED.\n",
    "#             # time_shift = - (self.time_duration - time_d)\n",
    "#             time_shift = time_d\n",
    "#             h_d = h_d.cyclic_time_shift(time_shift)\n",
    "#             h_d.start_time = h_d.start_time + time_shift\n",
    "\n",
    "#             # whiten\n",
    "#             h_d = h_d / (_get_psd(ifo, psd, h_d.delta_f, f_max, f_min_psd, event_dir) ** 0.5)\n",
    "\n",
    "#             # Convert to TD if necessary, and ensure waveform is of correct length\n",
    "#             if prior_data.domain == 'TD':\n",
    "#                 h_d = h_d.to_timeseries().time_slice( -time_duration, 0.0)\n",
    "\n",
    "#             h_d_dict[ifo] = h_d.data\n",
    "\n",
    "#         out = h_d_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "inspect.getmembers(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.time_delay_from_earth_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.antenna_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.timeseries import TimeSeries\n",
    "from gwpy.frequencyseries import FrequencySeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwpy_h_d = FrequencySeries.from_pycbc(h_d)#.abs()\n",
    "gwpy_h_d.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwpy_h_d_td = TimeSeries.from_pycbc(h_d.to_timeseries())\n",
    "gwpy_h_d_td.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.23*(10e-3)*(10e6)/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key not in psd_dict[ifo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate arrays to store data - but we should never really need to do this, right?\n",
    "# h_detector = {ifo: torch.zeros((n_train, Nf), dtype=torch.complex64) for ifo in detectors}  # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FlowModel(pl.LightningModule):\n",
    "    \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model_dir: Union[Path, str]=None,\n",
    "#         data_dir: Union[Path, str]=None,\n",
    "#         device: Union[torch.device, str]='cuda',\n",
    "#     ):\n",
    "#         \"\"\"A FlowModel is a PyTorch LightningModule that we use for gravitational wave event modelling.\"\"\"\n",
    "#         super().__init__()\n",
    "#         self.device = torch.device(device)\n",
    "#         self.data_dir = data_dir\n",
    "#         self.model_dir = model_dir\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = np.random.randn(200)\n",
    "# x2 = np.random.randn(200) + 2\n",
    "\n",
    "# group_labels = ['Group 1', 'Group 2']\n",
    "\n",
    "# colors = ['slategray', 'magenta']\n",
    "\n",
    "# # Create distplot with curve_type set to 'normal'\n",
    "# fig = ff.create_distplot(\n",
    "#     [x1, x2],\n",
    "#     group_labels,\n",
    "#     bin_size=.5,\n",
    "#     show_hist=False,\n",
    "#     show_rug=False,\n",
    "#     curve_type='kde', # override default 'kde'\n",
    "#     colors=colors\n",
    "# )\n",
    "\n",
    "# # Add title\n",
    "# fig.update_layout(title_text='Distplot with Normal Distribution')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d plotly density chart\n",
    "# fig = px.density_contour(samples_df, x='mass_1', y='mass_2', marginal_x='histogram', marginal_y='histogram')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "astro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
